\documentclass[12pt]{amsart}

\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{bbold}
\usepackage{listings}
\usepackage{lineno}
\usepackage[margin=3cm]{geometry}
\usepackage[all,cmtip, color,matrix,arrow]{xy}
\usepackage{amsaddr}
\usepackage{tikz-cd}
\usepackage{amsmath}%To use \text 
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage[capitalize]{cleveref}
\crefname{thm}{Theorem}{Theorems}
%\usepackage{bbold}
\usepackage[export]{adjustbox}
\usepackage{todonotes}
\usepackage{bm}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{mathtools}
\usepackage{aliascnt}
\newaliascnt{eqfloat}{equation}
\newfloat{eqfloat}{h}{eqflts}
\floatname{eqfloat}{Equation}
\usepackage{dirtytalk}
\usepackage[mathscr]{euscript}

\newcommand*{\ORGeqfloat}{}
\let\ORGeqfloat\eqfloat
\def\eqfloat{%
  \let\ORIGINALcaption\caption
  \def\caption{%
    \addtocounter{equation}{-1}%
    \ORIGINALcaption
  }%
  \ORGeqfloat
}
\newcommand{\raul}[1]{\todo[color=green!30,inline]{Raul: #1}}


\makeatletter
\providecommand*{\shuffle}{%
  \mathbin{\mathpalette\shuffle@{}}%
}
\newcommand*{\shuffle@}[2]{%
  % #1: math style
  % #2: unused
  \sbox0{$#1\vcenter{}$}%
  \kern .15\ht0 % side bearing
  \rlap{\vrule height .25\ht0 depth 0pt width 2.5\ht0}%
  \raise.1\ht0\hbox to 2.5\ht0{%
    \vrule height 1.75\ht0 depth -.1\ht0 width .17\ht0 %
    \hfill
    \vrule height 1.75\ht0 depth -.1\ht0 width .17\ht0 %
    \hfill
    \vrule height 1.75\ht0 depth -.1\ht0 width .17\ht0 %
  }%
  \kern .15\ht0 % side bearing
}
\makeatother

%\def\shuffle{\sqcup\mathchoice{\mkern-7mu}{\mkern-7mu}{\mkern-3.2mu}{\mkern-3.8mu}\sqcup\,}
\newcommand{\qshuffle}{\overline{\shuffle}}


\theoremstyle{definition}
\newtheorem{thm}{Theorem}[section]
\newtheorem{prop}[thm]{Proposition}
\newtheorem{lm}[thm]{Lemma}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{obs}[thm]{Observation}
\newtheorem{defin}[thm]{Definition}
\newtheorem{smpl}[thm]{Example}
\newtheorem{quest}[thm]{Question}
\newtheorem{prob}[thm]{Problem}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{rem}[thm]{Remark}
\crefname{lm}{Lemma}{Lemmas}
\crefname{thm}{Theorem}{Theorems}
\crefname{prop}{Proposition}{Propositions}
\crefname{defin}{Definition}{Definitions}
\crefname{rem}{Remark}{Remarks}

\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\F}{\mathbb{F}}

\newcommand{\one}{\mathbb{1}}

\newcommand{\CC}{\mathcal C}
\newcommand{\JJ}{\mathcal J}
\newcommand{\II}{\mathcal I}
\newcommand{\FF}{\mathcal F}

%vectors
\newcommand{\vv}{\mathsf{v}}
\newcommand{\vj}{\mathsf{j}}
\newcommand{\vx}{\mathsf{x}}

\newcommand{\spn}{\mathrm{span}}
\newcommand{\rk}{\mathrm{rk}}


\begin{document}

%% Title, authors and addresses
\title{Lecture notes on algebraic methods in combinatorics} % Subtitle

\author{Raul Penaguiao}
\email{raul.penaguiao@mis.mpg.de}
\address{Max Planck Institute for the Sciences Leipzig}
\keywords{algebraic combinatorics, combinatorial nullstellensatz}
\subjclass[2010]{}
\date{Spring semester 2023} % Date

%\begin{abstract}
%\end{abstract}

\maketitle


\section{Preliminary definitions}

We denote the set $\{1, \dots, n\}$ by $[n]$.
Whenever $q$ is a power of a prime, we denote the unique field of cardinality $q$ by $\F_q$.
When $q$ is a prime number, we identify $\F_q$ with $\Z/_{q\Z}$.

\section{Combinatorics}

\subsection{Clubs with rules}


\begin{prop}[Oddtown]
Let $E$ be a finite set.
A family $\CC \subset 2^E $ is called an \textbf{oddtown} if
\begin{itemize}
\item Every $C \in \CC $ has an odd number of elements.

\item For two distinct $C, D \in \CC$, the set $C\cap D$ has an even number of elements.
\end{itemize}

Then, for any oddtown we have $|\CC| \leq |E|$
\end{prop}


\begin{proof}
We work in $\F_2^E$.
For each $C \in \CC$, let $\vv_C$ be the vector in $\F_2^E$ such that 
$$ (\vv_C)_i =\begin{cases*}
      & 1 \text{ if $i \in C$,}\\
      & 0 \text{ otherwise.}
    \end{cases*} $$

The first and second oddtown conditions give us respectively $\vv_C \cdot \vv_C = 1$ and $\vv_C \cdot \vv_D = 0 $ for any distinct $C, D \in \CC$.

We claim that $\{\vv_C\}_{C \in \CC}$ is a linearly independent set in $\F_2^E$.
It follows imediately that $|\CC| \leq |E|$.
Indeed, if $\sum_{C \in \CC} \alpha_C \vv_C = 0$ for scalars $\alpha_i$, then
$$ 0 = 0 \cdot \vv_D = \sum_{C \in \CC} \alpha_C \vv_C\cdot \vv_D = \alpha_D\, ,$$
for any $j \in \CC$, concluding the proof.
\end{proof}


\begin{prop}[Separated collections]
Let $E$ be a finite set.
A family $\CC \subset 2^E $ is called \textbf{separated} if for any two disjoint non-empty subfamilies $\II, \JJ \subseteq \CC$ we have $\bigcup_{I\in\II} I \neq \bigcup_{J\in\JJ} J$.

Then, for any separated family we have $|\CC| \leq |E|$.
\end{prop}


\begin{proof}
This time we work in $\R^E$.
For each $C \in \CC$, let $\vv_C$ be the vector in $\R^E$ such that 
$$ (\vv_C)_i =\begin{cases*}
      & 1 \text{ if $i \in C$,}\\
      & 0 \text{ otherwise.}
    \end{cases*} $$


We will show that $ \{ \vv_C\}_{C\in \CC}$ is a linearly independent set in $\R^E$.
That $|\CC| \leq |E|$ follows imediately.

Indeed, assume that $\sum_{C \in \CC} \alpha_C \vv_C = 0$.
Let $\II = \{C \in \CC | \alpha_C > 0\}$ and $\JJ = \{C \in \CC | \alpha_C < 0\}$.
Rearranging the equation above we have
$$\vv \coloneqq \sum_{C \in \II} \alpha_C \vv_C  = \sum_{C \in \JJ} (- \alpha_C) \vv_C\, .$$
Let $K = \{i \in E| \vv_i \neq 0\}$.
We have both that $\bigcup_{I\in\II} I = K$ and $\bigcup_{J\in\JJ} J = K$.
Also, $\II$ and $\JJ$ are disjoint.

This contradicts the fact that $\CC$ is separated unless $\II$ and $\JJ$ are empty.
But $\II$ and $\JJ$ empty implies $\alpha_C = 0 $ for any $C \in \CC$.
This shows that $ \{ \vv_C\}_{C\in \CC}$ is a linearly independent set, concluding the proof.
\end{proof}




\begin{prop}[Lindstorm's lemma]
Let $E$ be a finite set.
A family $\CC \subset 2^E $ is called \textbf{weakly separated} if for any two disjoint subfamilies $\II, \JJ \subseteq \CC$ we have $\bigcup_{I\in\II} I \neq \bigcup_{J\in\JJ} J$ or $\bigcap_{I\in\II} I \neq \bigcap_{J\in\JJ} J$.

Then, for any weakly separated family we have $|\CC| \leq |E| + 1$.
\end{prop}

\begin{proof}
This time we work in $\R_2^{E \uplus \{ \star \}}$.
For each $C \in \CC$, let $\vv_C$ be the vector in $\R_2^{E \uplus \{ \star \}}$ such that 
$$ (\vv_C)_i =\begin{cases*}
      & 1 \text{ if $i \in C$ or if $i = \star$,}\\
      & 0 \text{ otherwise.}
    \end{cases*} $$


We will show that $\{ \vv_C\}_{C\in \CC}$ is a linearly independent set in $\R^{E \uplus \{ \star \}}$.
That $|\CC| \leq |E|+1$ follows imediately.

Indeed, as before assume that $\sum_{C \in \CC} \alpha_C \vv_C = 0$.
Let $\II = \{C \in \CC | \alpha_C > 0\}$ and $\JJ = \{C \in \CC | \alpha_C < 0\}$.
Rearranging the equation above we have
$$\vv \coloneqq \sum_{C \in \II} \alpha_C \vv_C  = \sum_{C \in \JJ} (- \alpha_C) \vv_C\, .$$
Let $K = \{i \in E| \vv_i \neq 0\}$.
We have both that $\bigcup_{I\in\II} I = K$ and $\bigcup_{J\in\JJ} J = K$.
Also, $\II$ and $\JJ$ are disjoint.
Furthermore, $\vv_{\star } = \sum_{I \in \II} \alpha_I = - \sum_{J \in \JJ} \alpha_J$.
We can see that $i \in \bigcap_{I \in \II} I$ if and only if $\vv_i = \vv_{\star }$.
Similarly, $j \in \bigcap_{J \in \JJ} J$ if and only if $\vv_j = \vv_{\star }$.
We conclude that $\bigcap_{I \in \II} I = \bigcap_{J \in \JJ} J$.

This contradicts the fact that $\CC$ is weakly separated unless $\II$ and $\JJ$ are non-empty.
This shows that $ \{ \vv_C\}_{C\in \CC}$ is a linearly independent set, concluding the proof.
\end{proof}


\begin{prop}[Fischer's inequality]
Let $E$ be a finite set.
A family $\CC \subseteq 2^E$ is said to be $\lambda$\textbf{-Fischer} if $|C\cap D| = \lambda$ for all distinct $C, D \in \CC$.

Then, for any $\lambda$-Fischer family, if $\lambda \neq 0$ then $|\CC| \leq |E|$.
\end{prop}


\begin{proof}
We first deal with the case where $|C| = \lambda $ for some $C \in \CC$.
Then $\II \coloneqq \{ D \setminus C | D \in \CC \setminus \{C\} \}$ is a family of disjoint sets in $E \setminus C$, therefore
$$ |\II| \leq |E\setminus C| = |E| - \lambda \leq |E| - 1\, .$$
We conclude that $|\CC| \leq |E|$.

Now assume that $|C| > \lambda $ for all $C \in \CC$.
Define the vectors $\vv_C$ in $\R^E$ as 
$$ (\vv_C)_i =\begin{cases*}
      & 1 \text{ if $i \in C$,}\\
      & 0 \text{ otherwise.}
    \end{cases*} $$
Let $A$ be the $|E| \times |\CC|$ matrix with column vectors $\vv_C$.

We write $\one $ for the all one vector with $|\CC|$ entries, and so $\one \one^T$ is the all one matrix.
We have that $A^T A  = \lambda \one \one^T + \mathrm{diag}(d_1, \dots, d_{|E|})$.
Because $|C| > \lambda$ for all $C \in \CC$, each $d_i$ is a positive integer.

We now show that $A^T A$ is full rank.
Assume that $A^T A \vx = 0$, let $s = \one^T \vx = \sum_i \vx_i$.
Then, from the equation above and recalling that $d_i > 0$, 
\begin{align*}
A^T A \vx &= \lambda s \one + \mathrm{diag}(d_1, \cdots, d_{|\CC|}) \vx = 0\, , \\
x_i &= -\frac{\lambda s}{d_i} \, , \\
s = \sum_i x_i &= -s \lambda \sum_i\frac{1}{d_i}
\end{align*}

This implies that $s = 0$, which gives $\vx = 0$, or implies $1 = -\lambda \sum_i\frac{1}{d_i} < 0$ which is impossible.
Thus, $A^T A$ is a matrix of rank $|\CC|$, therefore $\rk A \geq |\CC|$, so $|\CC| \leq |E|$
\end{proof}


\begin{prop}[Generalised Fischer inequality]
Let $E$ be a finite set, $p$ a prime and $L = \{l_1, \ldots , l_s\} \subseteq \F_p$.
A family $\FF \subseteq 2^E$ is said to be $L$-Fischer if any two distinct $A, B \in \FF $ have $|A\cap B| \mod p \in L$.

Then $|\FF| \leq \sum_{i=0}^s \binom{n}{i}$.
\end{prop}

\begin{proof}
We work in $\F_p^E$.
For each $F \in \FF$, let $\vv_F$ be the vector in $\F_p^E$ as above, and define the following polynomials in $\Z[x_e | e \in E]$:
$$f_F(\vx) \coloneqq \prod_{i = 1}^s (\vx \cdot \vv_F - \ell_i ) \, .$$

Note that for $A, B \in \FF$ distinct, we have $f_A(\vv_B) = 0$, whereas $f_A(\vv_A) \neq 0$.
We now rewrite each $f_F$ by replacing any monomial of the form $\prod_{e\in E}x_e^{\alpha_e}$ with $\prod_{\substack{e\in E\\ \alpha_E > 0}}x_e$.
It is still the case that for $A, B \in \FF$ distinct, we have $f_A(\vv_B) = 0$, whereas $f_A(\vv_A) \neq 0$.

We claim that $\{ f_F \}_{F \in \FF}$ is a linearly independent set.
Furthermore, each polynomial $f_F$ is in the vector space spanned by $\spn\{\prod_{e \in A} x_e | \, A \subseteq E, \, |A| \leq l \}$, so the theorem follows.

Indeed, is $\sum_{F \in \FF} f_F \alpha_F =0$, then evaluating at $\vv_F $ gives us that, for each $F \in \FF$, $\alpha_F f_F(\vv_F) = 0$. 
We conclude that $\{ f_F \}_{F \in \FF}$ is a linearly independent set.
\end{proof}

\begin{prop}[Frankl-Wilson theorem]
Let $E$ be a finite set and $L = \{l_1, \ldots , l_s\} \subseteq \Z$.
A family $\FF \subseteq 2^E$ is said to be $L$-Fischer if any two distinct $A, B \in \FF $ have $|A\cap B| \in L$.

Then $|\FF| \leq \sum_{i=0}^s \binom{n}{i}$.
\end{prop}

Remark that, this time, we do not require $|A|\not\in L$, unlike in the $p$-adic case.

\begin{proof}
We work in $\Z^E$.
Write $\FF = \{F_1, \ldots , F_k\}$ with $|F_1| \leq |F_2| \leq \ldots \leq |F_k|$.
For each $F \in \FF$, let $\vv_F$ be the vector in $\Z^E$ as above, and define for $i= 1, \ldots , k$ the following polynomials in $\Z[x_e | e \in E]$:
$$f_i(\vx) \coloneqq \prod_{j : l_j < |F_i|} (\vx \cdot \vv_{F_i} - \ell_j ) \, .$$

Note that for $i < j \in [k]$, we have $f_j(\vv_{F_i}) = 0$, whereas $f_i(\vv_{F_i}) \neq 0$.
We now rewrite each $f_j$ by replacing any monomial of the form $\prod_{e\in E}x_e^{\alpha_e}$ with $\prod_{\substack{e\in E\\ \alpha_E > 0}}x_e$.
It can be observed that it is still the case that for $i < j \in [k]$, we have $f_j(\vv_{F_i}) = 0$, whereas $f_i(\vv_{F_i}) \neq 0$.

We claim that $\{ f_F \}_{F \in \FF}$ is a linearly independent set.
Furthermore, each polynomial $f_F$ is in the vector space spanned by $\prod_{A\subseteq E}$ with $|A| \leq l$, so the theorem follows.

Indeed, is $\sum_{i = 1}^k f_{F_i} \alpha_i =0$, let $j$ be the index such that $\alpha_j \neq 0$.
But then evaluating at $\vv_{F_j} $ gives us that $\alpha_j f_j(\vv_{F_j}) = 0$. 
We conclude that $\{ f_F \}_{F \in \FF}$ is a linearly independent set.
\end{proof}


\begin{prop}[$p$-adic Frankl-Wilson theorem]

\end{prop}
\begin{proof}

\end{proof}


\begin{prop}[Ray-Chaudhuri-Wilson theorem]
\end{prop}


\subsection{Graph theory}

\subsubsection{Turan's problem}

\subsubsection{Consistent coloring}

\subsubsection{Ramsey theory}

\section{Geometry}

\subsubsection*{Joints Problem}

A \textbf{joint} in a collection $\mathcal L$ of lines in $\R^3$ is an intersection of at least three non-coplanar lines.


\begin{prop}
Given $N$ lines in $\R^2$ forming $J$ joints we have that
$$ J \leq C N^{3/_2}\, ,$$
furthermore, this bound is tight.
\end{prop}


\begin{proof}
First we show that this is indeed tight.
Incidentally, take an integer $n$, we can find $3n^2$ lines that intersect in $n^3$ joints. For $n=3$ we can see the example in \cref{fig:joints}.
The general construction is as follows: we take the collection of $n^2$ lines with direction $(0, 0, 1)$ that go through $(a, b, 0)$, where $a, b\in [n]$, and take it together with two rotations of $120^o$ and $240^o$ of this set along the axis $\{x = y = z\}$.

\begin{figure}[h]
\includegraphics[scale=.1]{../imgs/ina.png}%../imgs/joints
\caption{A construction of a collection of lines with high number of joints.\label{fig:joints}}
\end{figure}

Now, we establish the inequality for $C = 3^{3/_2}$.
First, we show that for any collection of lines $\mathcal L$, there is a line with at most $3 J^{1/_3}$ joints.
Acting by contradiction, assume otherwise and consider a polynomial $p \in \R[x, y, z]$ such that 
\begin{enumerate}
\item It is non-zero;

\item It vanishes at all joints;

\item It has degree at most $J^{1/_3}$ on each variable.
\end{enumerate}

Because a polynomial satisfying item 3 can be written as a combination of $(\lfloor J^{1/_3}\rfloor + 1)^3$ monomials, item 2 amounts to $J$ linear equations, such a non-zero polynomial exists.
We pick $p$ that minimizes the degree, and consider the polynomial
$$q \coloneqq \left(\frac{\partial}{\partial x} + \frac{\partial}{\partial y} + \frac{\partial}{\partial z} \right) p \, .$$

The polynomial $p$ restricted to any line is a polynomial of degree at most $3J^{1/_3}$.
Because each line has, by contradiction hypothesis, at least $3 J^{1/_3} + 1$ joints, this polynomial must be identically zero in each line.

It follows that all directional derivatives of $p$ at each joint $\vj$ vanish, so $q(\vj) = 0$.
Furthermore, $q$ also satisfies item 3 and has smaller degree than $p$.
By minimality, we must have $q \equiv 0$, which means that 
$$ p(x, y, zz ) = ax +by + cz \, ,$$
for some coefficients $a, b, c$.


We conclude the proof by acting on induction. For $N = 3$ we necessarily have $J\leq 1 \leq 3^{3/_2} 3^{3/_2}$.
No consider a collection of lines $\mathcal L$, and find the one line $\ell \in \mathcal L$ that has at most $3 J^{1/_3}$ joints.
By induction hypothesis, there are at most $3^{3/_2} (N-1)^{3/_2}$ joints in $\mathcal L \setminus \{\ell \}$, so 
$$ J \leq 3 J^{1/_3} + 3^{3/_2} (N-1)^{3/_2}\, , $$
as desired.
\end{proof}

\subsection*{Aknowledgments}
The author is supported by the Max Planck institute for the sciences. 
These notes are based on a lecture by Benny Sudakov at ETH, in 2014.

\bibliographystyle{alpha}
\bibliography{bibli}



\end{document}
