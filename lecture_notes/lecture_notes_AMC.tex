\documentclass[12pt]{amsart}

\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{bbold}
\usepackage{listings}
\usepackage{lineno}
\usepackage[margin=3cm]{geometry}
\usepackage[all,cmtip, color,matrix,arrow]{xy}
\usepackage{amsaddr}
\usepackage{tikz-cd}
\usepackage{amsmath}%To use \text 
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage[capitalize]{cleveref}
\crefname{thm}{Theorem}{Theorems}
%\usepackage{bbold}
\usepackage[export]{adjustbox}
\usepackage{todonotes}
\usepackage{bm}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{mathtools}
\usepackage{aliascnt}
\newaliascnt{eqfloat}{equation}
\newfloat{eqfloat}{h}{eqflts}
\floatname{eqfloat}{Equation}
\usepackage{dirtytalk}
\usepackage[mathscr]{euscript}

\newcommand*{\ORGeqfloat}{}
\let\ORGeqfloat\eqfloat
\def\eqfloat{%
  \let\ORIGINALcaption\caption
  \def\caption{%
    \addtocounter{equation}{-1}%
    \ORIGINALcaption
  }%
  \ORGeqfloat
}
\newcommand{\raul}[1]{\todo[color=green!30,inline]{Raul: #1}}


\makeatletter
\providecommand*{\shuffle}{%
  \mathbin{\mathpalette\shuffle@{}}%
}
\newcommand*{\shuffle@}[2]{%
  % #1: math style
  % #2: unused
  \sbox0{$#1\vcenter{}$}%
  \kern .15\ht0 % side bearing
  \rlap{\vrule height .25\ht0 depth 0pt width 2.5\ht0}%
  \raise.1\ht0\hbox to 2.5\ht0{%
    \vrule height 1.75\ht0 depth -.1\ht0 width .17\ht0 %
    \hfill
    \vrule height 1.75\ht0 depth -.1\ht0 width .17\ht0 %
    \hfill
    \vrule height 1.75\ht0 depth -.1\ht0 width .17\ht0 %
  }%
  \kern .15\ht0 % side bearing
}
\makeatother

%\def\shuffle{\sqcup\mathchoice{\mkern-7mu}{\mkern-7mu}{\mkern-3.2mu}{\mkern-3.8mu}\sqcup\,}
\newcommand{\qshuffle}{\overline{\shuffle}}


\theoremstyle{definition}
\newtheorem{thm}{Theorem}[section]
\newtheorem{prop}[thm]{Proposition}
\newtheorem{lm}[thm]{Lemma}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{obs}[thm]{Observation}
\newtheorem{defin}[thm]{Definition}
\newtheorem{smpl}[thm]{Example}
\newtheorem{quest}[thm]{Question}
\newtheorem{prob}[thm]{Problem}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{rem}[thm]{Remark}
\crefname{lm}{Lemma}{Lemmas}
\crefname{thm}{Theorem}{Theorems}
\crefname{prop}{Proposition}{Propositions}
\crefname{defin}{Definition}{Definitions}
\crefname{rem}{Remark}{Remarks}

\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\F}{\mathbb{F}}

\newcommand{\one}{\mathbb{1}}

\newcommand{\CC}{\mathcal C}
\newcommand{\JJ}{\mathcal J}
\newcommand{\II}{\mathcal I}
\newcommand{\FF}{\mathcal F}

%vectors
\newcommand{\vv}{\mathsf{v}}
\newcommand{\vj}{\mathsf{j}}
\newcommand{\vx}{\mathsf{x}}

\newcommand{\spn}{\mathrm{span}}
\newcommand{\rk}{\mathrm{rk}}


\begin{document}

%% Title, authors and addresses
\title{Lecture notes on algebraic methods in combinatorics} % Subtitle

\author{Raul Penaguiao}
\email{raul.penaguiao@mis.mpg.de}
\address{Max Planck Institute for the Sciences Leipzig}
\keywords{algebraic combinatorics, combinatorial nullstellensatz}
\subjclass[2010]{}
\date{Spring semester 2023} % Date

%\begin{abstract}
%\end{abstract}

\maketitle


\section{Preliminary definitions}

We denote the set $\{1, \dots, n\}$ by $[n]$.
Whenever $q$ is a power of a prime, we denote the unique field of cardinality $q$ by $\F_q$.
When $q$ is a prime number, we identify $\F_q$ with $\Z/_{q\Z}$.

\section{Combinatorics}

\subsection{Clubs with rules}


\begin{prop}[Oddtowns]
Let $E$ be a finite set.
A family $\CC \subset 2^E $ is called an \textbf{oddtown} if
\begin{itemize}
\item Every $C \in \CC $ has an odd number of elements.

\item For two distinct $C, D \in \CC$, the set $C\cap D$ has an even number of elements.
\end{itemize}

Then, for any oddtown we have $|\CC| \leq |E|$
\end{prop}


\begin{proof}
We work in $\F_2^E$.
For each $C \in \CC$, let $\vv_C$ be the vector in $\F_2^E$ such that 
$$ (\vv_C)_i =\begin{cases*}
      & 1 \text{ if $i \in C$,}\\
      & 0 \text{ otherwise.}
    \end{cases*} $$

The first and second oddtown conditions give us respectively $\vv_C \cdot \vv_C = 1$ and $\vv_C \cdot \vv_D = 0 $ for any distinct $C, D \in \CC$.

We claim that $\{\vv_C\}_{C \in \CC}$ is a linearly independent set in $\F_2^E$.
It follows imediately that $|\CC| \leq |E|$.
Indeed, if $\sum_{C \in \CC} \alpha_C \vv_C = 0$ for scalars $\alpha_C \in \F_2$, then
$$ 0 = 0 \cdot \vv_D = \sum_{C \in \CC} \alpha_C \vv_C\cdot \vv_D = \alpha_D\, ,$$
for any $D \in \CC$, concluding the proof.
\end{proof}


\begin{prop}[Separated collections]
Let $E$ be a finite set.
A family $\CC \subset 2^E $ is called \textbf{separated} if for any two disjoint non-empty subfamilies $\II, \JJ \subseteq \CC$ we have $\bigcup_{I\in\II} I \neq \bigcup_{J\in\JJ} J$.

Then, for any separated family we have $|\CC| \leq |E|$.
\end{prop}


\begin{proof}
This time we work in $\R^E$.
For each $C \in \CC$, let $\vv_C$ be the vector in $\R^E$ such that 
$$ (\vv_C)_i =\begin{cases*}
      & 1 \text{ if $i \in C$,}\\
      & 0 \text{ otherwise.}
    \end{cases*} $$


We will show that $ \{ \vv_C\}_{C\in \CC}$ is a linearly independent set in $\R^E$.
That $|\CC| \leq |E|$ follows imediately.

Indeed, assume that $\sum_{C \in \CC} \alpha_C \vv_C = 0$.
Let $\II = \{C \in \CC | \alpha_C > 0\}$ and $\JJ = \{C \in \CC | \alpha_C < 0\}$.
Rearranging the equation above we have
$$\vv \coloneqq \sum_{C \in \II} \alpha_C \vv_C  = \sum_{C \in \JJ} (- \alpha_C) \vv_C\, .$$
Let $K = \{i \in E| \vv_i \neq 0\}$.
We have both that $\bigcup_{I\in\II} I = K$ and $\bigcup_{J\in\JJ} J = K$.
Also, $\II$ and $\JJ$ are disjoint.

This contradicts the fact that $\CC$ is separated unless $\II$ and $\JJ$ are empty.
But $\II$ and $\JJ$ empty implies $\alpha_C = 0 $ for any $C \in \CC$.
This shows that $ \{ \vv_C\}_{C\in \CC}$ is a linearly independent set, concluding the proof.
\end{proof}




\begin{prop}[Lindstorm's lemma]
Let $E$ be a finite set.
A family $\CC \subset 2^E $ is called \textbf{weakly separated} if for any two disjoint subfamilies $\II, \JJ \subseteq \CC$ we have $\bigcup_{I\in\II} I \neq \bigcup_{J\in\JJ} J$ or $\bigcap_{I\in\II} I \neq \bigcap_{J\in\JJ} J$.

Then, for any weakly separated family we have $|\CC| \leq |E| + 1$.
\end{prop}

\begin{proof}
This time we work in $\R^{E \uplus \{ \star \}}$.
For each $C \in \CC$, let $\vv_C$ be the vector in $\R^{E \uplus \{ \star \}}$ such that 
$$ (\vv_C)_i =\begin{cases*}
      & 1 \text{ if $i \in C$ or if $i = \star$,}\\
      & 0 \text{ otherwise.}
    \end{cases*} $$


We will show that $\{ \vv_C\}_{C\in \CC}$ is a linearly independent set in $\R^{E \uplus \{ \star \}}$.
That $|\CC| \leq |E|+1$ follows imediately.

Indeed, as before assume that $\sum_{C \in \CC} \alpha_C \vv_C = 0$.
Let $\II = \{C \in \CC | \alpha_C > 0\}$ and $\JJ = \{C \in \CC | \alpha_C < 0\}$.
Rearranging the equation above we have
$$\vv \coloneqq \sum_{C \in \II} \alpha_C \vv_C  = \sum_{C \in \JJ} (- \alpha_C) \vv_C\, .$$
Let $K = \{i \in E| \vv_i \neq 0\}$.
We have both that $\bigcup_{I\in\II} I = K$ and $\bigcup_{J\in\JJ} J = K$.
Also, $\II$ and $\JJ$ are disjoint.
Furthermore, $\vv_{\star } = \sum_{I \in \II} \alpha_I = - \sum_{J \in \JJ} \alpha_J$.
We can see that $i \in \bigcap_{I \in \II} I$ if and only if $\vv_i = \vv_{\star }$.
Similarly, $j \in \bigcap_{J \in \JJ} J$ if and only if $\vv_j = \vv_{\star }$.
We conclude that $\bigcap_{I \in \II} I = \bigcap_{J \in \JJ} J$.

This contradicts the fact that $\CC$ is weakly separated unless $\II$ and $\JJ$ are non-empty.
This shows that $ \{ \vv_C\}_{C\in \CC}$ is a linearly independent set, concluding the proof.
\end{proof}


\begin{prop}[Fischer's inequality]
Let $E$ be a finite set.
A family $\CC \subseteq 2^E$ is said to be $\lambda$\textbf{-Fischer} if $|C\cap D| = \lambda$ for all distinct $C, D \in \CC$.

Then, for any $\lambda$-Fischer family, if $\lambda \neq 0$ then $|\CC| \leq |E|$.
\end{prop}


\begin{proof}
We first deal with the case where $|C| = \lambda $ for some $C \in \CC$.
Then $\II \coloneqq \{ D \setminus C | D \in \CC \setminus \{C\} \}$ is a family of disjoint sets in $E \setminus C$, therefore
$$ |\II| \leq |E\setminus C| = |E| - \lambda \leq |E| - 1\, .$$
We conclude that $|\CC| \leq |E|$.

Now assume that $|C| > \lambda $ for all $C \in \CC$.
For $C \in \CC$, define the vectors $\vv_C$ in $\R^E$ as 
$$ (\vv_C)_i =\begin{cases*}
      & 1 \text{ if $i \in C$,}\\
      & 0 \text{ otherwise.}
    \end{cases*} $$
Let $A$ be the $|E| \times |\CC|$ matrix with column vectors $\vv_C$.

We write $\one $ for the all one vector with $|\CC|$ entries, which we also interpret as a $|\CC| \times 1$ matrix.
In this way, $\one \one^T$ is the all one matrix.
We have that $A^T A  = \lambda \one \one^T + \mathrm{diag}((d_C)_{C\in\CC})$, where $\mathrm{diag}((d_C)_{C\in\CC})$ is a diagonal matrix with entries $d_C$.
Because $|C| > \lambda$ for all $C \in \CC$, each $d_C$ is a positive integer.

We now show that $A^T A$ is full rank.
Because this is a square matrix, we is equivalently show that it is non-singular.
Assume that $A^T A \vx = 0$, let $s = \one^T \vx = \sum_{C \in \CC} \vx_C$.
Then, from the equation above and $d_i > 0$, we have
\begin{align*}
A^T A \vx &= \lambda s \one + \mathrm{diag}((d_C)_{C\in\CC}) \vx = 0\, , \\
x_i &= -\frac{\lambda s}{d_i} \, , \\
s = \sum_i x_i &= - \lambda s \sum_{C \in \CC}\frac{1}{d_C}
\end{align*}

This implies that $s = 0$, which gives $\vx = 0$, or implies $1 = -\lambda \sum_i\frac{1}{d_i} < 0$, which is impossible.
Thus, $A^T A$ is a matrix of rank $|\CC|$, therefore $\rk A \geq |\CC|$, so $|\CC| \leq |E|$
\end{proof}


\begin{prop}[Generalised Fischer inequality]
Let $E$ be a finite set, $p$ a prime and $L \subseteq \F_p$.
A family $\FF \subseteq 2^E$ is said to be $L$-Fischer if for any $A, B \in \FF $ we have $|A\cap B| \mod p \in L$ whenever $A \neq B$ and, furthermore, $|A| \mod p \not \in L$ for all $A \in \FF$.

Then $|\FF| \leq \sum_{i=0}^{|L|} \binom{|E|}{i}$.
\end{prop}

\begin{proof}
We work in $\F_p^E$.
For each $F \in \FF$, let $\vv_F$ be the vector in $\F_p^E$ as above, and define the following polynomials in $\Z[\vx_e | e \in E]$:
$$f_F(\vx) \coloneqq \prod_{\ell \in L} (\vx \cdot \vv_F - \ell ) \, .$$

Note that for $A, B \in \FF$ distinct, we have $f_A(\vv_B) = 0$, whereas $f_A(\vv_A) \neq 0$.
We now rewrite each $f_F$ by replacing any monomial of the form $\prod_{e\in E}\vx_e^{\alpha_e}$ with $\prod_{\substack{e\in E\\ \alpha_E > 0}}\vx_e$.
It is still the case that for $A, B \in \FF$ distinct, we have $f_A(\vv_B) = 0$, whereas $f_A(\vv_A) \neq 0$.

We claim that $\{ f_F \}_{F \in \FF}$ is a linearly independent set.
Furthermore, because $\deg f \leq s$, each polynomial $f_F$ is in the vector space $\spn\{\prod_{e \in A} \vx_e | \, A \subseteq E, \, |A| \leq |L| \}$, so the theorem follows.

Indeed, if $\sum_{F \in \FF} f_F \alpha_F =0$, then evaluating this zero polynomial at $\vx = \vv_F $ for each $F \in \FF$, gives us that $\alpha_F f_F(\vv_F) = 0$, so $\alpha_F = 0$. 
We conclude that $\{ f_F \}_{F \in \FF}$ is a linearly independent set.
\end{proof}

The following was shown in \cite{hsieh1975intersection}:

\begin{prop}[Frankl-Wilson theorem]
Let $E$ be a finite set and $L \subseteq \Z$.
A family $\FF \subseteq 2^E$ is said to be $L$-Fischer if any two distinct $A, B \in \FF $ have $|A\cap B| \in L$.

Then $|\FF| \leq \sum_{i=0}^{|L|} \binom{|E|}{i}$.
\end{prop}

Note that the meaning of $L$-Fischer is intrinsically different whenever $L \subseteq \Z$ and $L \subseteq \F_p$.
We hope that this flexibility of definition does not bring any ambiguity.
Remark that, this time, we do not require $|A|\not\in L$, unlike in the $p$-adic case.

\begin{proof}
We work in $\Z^E$.
Write $\FF = \{F_1, \ldots , F_k\}$ with $|F_1| \leq |F_2| \leq \ldots \leq |F_k|$.
For each $F \in \FF$, let $\vv_F$ be the vector in $\Z^E$ as above, and define for $i= 1, \ldots , k$ the following polynomials in $\Z[\vx_e | e \in E]$:
$$f_i(\vx) \coloneqq \prod_{ \substack{\ell \in L \\ \ell < |F_i|}} (\vx \cdot \vv_{F_i} - \ell) \, .$$

Note that for $i > j $ elements in $[k]$, we have $F_i \not\subseteq F_j$, thus $|F_j \cap F_i| <  |F_i|$.
So we have $f_i(\vv_{F_j}) = 0$, whereas $f_i(\vv_{F_i}) \neq 0$.
We now rewrite each $f_j$ by replacing any monomial of the form $\prod_{e\in E}\vx_e^{\alpha_e}$ with $\prod_{\substack{e\in E\\ \alpha_E > 0}}\vx_e$.
It can be observed that it is still the case that for $i > j $ elements in $[k]$, we have $f_i(\vv_{F_j}) = 0$, whereas $f_i(\vv_{F_i}) \neq 0$.

We claim that $\{ f_F \}_{F \in \FF}$ is a linearly independent set.
Furthermore, because $\deg f \leq s$, each polynomial $f_F$ is in the vector space  $\spn\{\prod_{e \in A} \vx_e | \, A \subseteq E, \, |A| \leq |L| \}$, which has dimension $\sum_{i=0}^{|L|} \binom{|E|}{i}$, so the theorem follows from the independence claim.

Indeed, if $\sum_{i = 1}^k f_{F_i} \alpha_i =0$, let $j$ be the smallest index such that $\alpha_j \neq 0$.
But then evaluating this zero polynomial at $\vx = \vv_{F_j} $ gives us that $\alpha_{F_j} f_j(\vv_{F_j}) = 0$, so $\alpha_F = 0$. 
We conclude that $\{ f_F \}_{F \in \FF}$ is a linearly independent set.
\end{proof}

The following was shown in \cite{ray1975t}:

\begin{prop}[Ray-Chaudhuri-Wilson theorem]
Let $E$ be a finite set, $\lambda $ be a positive integer and $L$ a set of positive integers smaller than $\lambda$.
Assume that $\FF $ is an $L$-Fischer collection of subsets of $E$, with $|F| = \lambda $ for each $F \in \FF$.
Then $|\FF| \leq \binom{|E|}{|L|}$.
\end{prop}

\begin{proof}
We work in $\Z^E$.
For each $I \subseteq E$, let $\vv_I$ be the vector in $\Z^E$ as above, and define for $F \in \FF$ the following polynomials in $\Z[\vx_e | e \in E]$:
$$f_F(\vx) \coloneqq \prod_{\ell \in L } (\vx \cdot \vv_{F} - \ell ) \, .$$

Note that for $F, G \in \FF$ distinct, we have $f_F(\vv_G) = 0$, whereas $f_F(\vv_F) = \prod_{\ell \in L } (\lambda - \ell )\neq 0$.
We now rewrite each $f_F$ by replacing any monomial of the form $\prod_{e\in E}\vx_e^{\alpha_e}$ with $\prod_{\substack{e\in E\\ \alpha_E > 0}}\vx_e$.
It can be observed that for $F, G \in \FF$, we still have $f_F(\vv_G) = 0$ if and only if $F \neq G$.


Furthermore, for $I\subseteq E$, define 
$$g_I(\vx) \coloneqq (\lambda - \sum_{i\in E} \vx_i)\prod_{i\in I} \vx_i\, .$$

Note that for sets $I, J$ in $E$, we have that $g_I(\vv_J ) = 0$ whenever $I\not\subseteq J$.
Furthermore, we have $g_I(\vv_F) = 0$ for any $F \in \FF$.
We now rewrite each $g_I$ by replacing any monomial of the form $\prod_{e\in E}x_e^{\alpha_e}$ with $\prod_{\substack{e\in E\\ \alpha_E > 0}}x_e$.
It is still the case that for sets $I, J$ in $E$, we have that $g_I(\vv_J ) = 0$ whenever $I\not\subseteq J$, as well as that $g_I(\vv_F) = 0$ for any $F \in \FF$.

We claim that $\{ f_F \}_{F \in \FF}\cup \{g_I \}_{I \, : |I| < |L| }$ is a linearly independent set.
Furthermore, because $\deg f_F \leq |L|$ for $F \in \FF$, and $\deg g_I \leq |L|$ for $|I| < |L|$, the polynomials $f_F$ and $g_I$ are in the vector space $\spn\{\prod_{e \in A} \vx_e | \, A \subseteq E, \, |A| \leq |L| \}$, which as dimension $\sum_{i=0}^{|L|} \binom{|E|}{i}$.
It follows that
$$ \sum_{i=0}^{|L|} \binom{|E|}{i} \geq \sum_{i=0}^{|L|-1} \binom{|E|}{i} + |\FF| \, ,$$
so $\binom{|E|}{|L|} \geq |\FF|$ follows from the independence claim.

Indeed, assume that 
\begin{equation}\label{eq:l_i_ness}
\sum_{F \in \FF} f_F \alpha_F + \sum_{\substack{I \subseteq E\\ |I| < |L|}} g_I \alpha_I =0 \, .
\end{equation}

For any $F \in \FF$, evaluating \eqref{eq:l_i_ness} at $\vx = \vv_F $ gives us that $\alpha_F f_F(\vv_F) = 0$, so $\alpha_F = 0$.

If there is some $I$ with $|I| < |L|$ and $\alpha_I \neq 0$, find such $I$ minimal by inclusion.
Then evaluating \eqref{eq:l_i_ness} in $\vv_I$, using that $\alpha_F = 0$ for any $F \in \FF$, gives us $\alpha_I g_I(\vv_I) = 0$, which implies $\alpha_I = 0$.
We conclude that $\{ f_F \}_{F \in \FF}\cup \{g_I \}_{I \, : |I| < |L| }$ is a linearly independent set.
\end{proof}


\begin{prop}[Frankl - Wilson]
Let $E$ be a finite set, $p$ a prime number, $\lambda$ a positive integer and $L$ a collection of elements in $\F_p$.
Assume that $\lambda \mod p\not\in L$ and that $|L| \leq \lambda < p$.


If $\FF$ is $L$-Fischer and $|F| = \lambda $ for each $F \in \FF$, then $|\FF| \leq \binom{|E|}{|L|}$.
\end{prop}

\begin{proof}
We work in $\F_p^E$.
For each $I \subseteq E$, let $\vv_I$ be the vector in $\F_p^E$ as above, and define for $F \in \FF$ the following polynomials in $\Z[\vx_e | e \in E]$:
$$f_F(\vx) \coloneqq \prod_{\ell \in L } (\vx \cdot \vv_{F} - \ell ) \, .$$

Note that for $F, G \in \FF$ distinct, we have $f_F(\vv_G) = 0$, whereas $f_F(\vv_F) = \prod_{\ell \in L } (\lambda - \ell )\neq 0$.
We now rewrite each $f_F$ by replacing any monomial of the form $\prod_{e\in E}\vx_e^{\alpha_e}$ with $\prod_{\substack{e\in E\\ \alpha_E > 0}}\vx_e$.
It can be observed that for $F, G \in \FF$, we still have $f_F(\vv_G) = 0$ if and only if $F \neq G$.

Furthermore, for $I\subseteq E$, define 
$$g_I(\vx) \coloneqq (\lambda - \sum_{i\in E} \vx_i)\prod_{i\in I} \vx_i\, .$$

Note that for sets $I, J$ in $E$, we have that $g_I(\vv_J ) = 0$ whenever $I\not\subseteq J$.
Note that $g_I(\vv_I) \neq 0$ whenever $|I| < |L|$, thanks to the condition $|L| \leq \lambda < p$.

Furthermore, we have $g_I(\vv_F) = 0$ for any $F \in \FF$.
We now rewrite each $g_I$ by replacing any monomial of the form $\prod_{e\in E}x_e^{\alpha_e}$ with $\prod_{\substack{e\in E\\ \alpha_E > 0}}x_e$.
It is still the case that for sets $I, J$ in $E$, we have that $g_I(\vv_J ) = 0$ whenever $I\not\subseteq J$, that $g_I(\vv_I) \neq 0$ for $|I| < |L|$ as well as that $g_I(\vv_F) = 0$ for any $F \in \FF$.

We claim that $\{ f_F \}_{F \in \FF}\cup \{g_I \}_{I \, : |I| < |L| }$ is a linearly independent set.
Furthermore, because $\deg f_F \leq |L|$ for $F \in \FF$, and $\deg g_I \leq |L|$ for $|I| < |L|$, the polynomials $f_F$ and $g_I$ are in the vector space $\spn\{\prod_{e \in A} \vx_e | \, A \subseteq E, \, |A| \leq |L| \}$, which as dimension $\sum_{i=0}^{|L|} \binom{|E|}{i}$.
It follows that
$$ \sum_{i=0}^{|L|} \binom{|E|}{i} \geq \sum_{i=0}^{|L|-1} \binom{|E|}{i} + |\FF| \, ,$$
so $\binom{|E|}{|L|} \geq |\FF|$ follows from the independence claim, which is done exactly as above.
\end{proof}

%Indeed, assume that 
%\begin{equation}\label{eq:l_i_ness}
%\sum_{F \in \FF} f_F \alpha_F + \sum_{\substack{I \subseteq E\\ |I| < |L|}} g_I \alpha_I =0 \, .
%\end{equation}
%
%For any $F \in \FF$, evaluating \eqref{eq:l_i_ness} at $\vx = \vv_F $ gives us that $\alpha_F f_j(\vv_F) = 0$, so $\alpha_F = 0$.
%
%If there is some $I$ with $|I| < |L|$ and $\alpha_I \neq 0$, find such $I$ minimal by inclusion.
%Then evaluating \eqref{eq:l_i_ness} in $\vv_I$, using that $\alpha_F = 0$ for any $F \in \FF$, gives us $\alpha_I g_I(\vv_I) = 0$, which implies $\alpha_I = 0$.
%We conclude that $\{ f_F \}_{F \in \FF}\cup \{g_I \}_{I \, : |I| < |L| }$ is a linearly independent set.

\subsection{Graph theory}

\subsubsection{Turan's problem}

\subsubsection{Consistent coloring}

\subsubsection{Ramsey theory}
The central problem in \textbf{Ramsey theory} is computing the minimal $R \coloneqq R(m, n)$ such that any edge colouring of $K_R$ into two colours contains either a monochromatic $K_m$ of a monochromatic $K_n$.


The first few values are the following:

\begin{tabular}{l| }

\end{tabular}




\section{Geometry}

\subsubsection*{Joints Problem}




A \textbf{joint} in a collection $\mathcal L$ of lines in $\R^3$ is an intersection of at least three non-coplanar lines.


\begin{prop}
Given $N$ lines in $\R^2$ forming $J$ joints we have that
$$ J \leq C N^{3/_2}\, ,$$
furthermore, this bound is tight.
\end{prop}


\begin{proof}
First we show that this is indeed tight.
Incidentally, take an integer $n$, we can find $3n^2$ lines that intersect in $n^3$ joints. For $n=3$ we can see the example in \cref{fig:joints}.
The general construction is as follows: we take the collection of $n^2$ lines with direction $(0, 0, 1)$ that go through $(a, b, 0)$, where $a, b\in [n]$, and take it together with two rotations of $120^o$ and $240^o$ of this set along the axis $\{x = y = z\}$.

\begin{figure}[h]
\includegraphics[scale=.1]{../imgs/ina.png}%../imgs/joints
\caption{A construction of a collection of lines with high number of joints.\label{fig:joints}}
\end{figure}

Now, we establish the inequality for $C = 3^{3/_2}$.
First, we show that for any collection of lines $\mathcal L$, there is a line with at most $3 J^{1/_3}$ joints.
Acting by contradiction, assume otherwise and consider a polynomial $p \in \R[x, y, z]$ such that 
\begin{enumerate}
\item It is non-zero;

\item It vanishes at all joints;

\item It has degree at most $J^{1/_3}$ on each variable.
\end{enumerate}

Because a polynomial satisfying item 3 can be written as a combination of $(\lfloor J^{1/_3}\rfloor + 1)^3$ monomials, item 2 amounts to $J$ linear equations, such a non-zero polynomial exists.
We pick $p$ that minimizes the degree, and consider the polynomial
$$q \coloneqq \left(\frac{\partial}{\partial x} + \frac{\partial}{\partial y} + \frac{\partial}{\partial z} \right) p \, .$$

The polynomial $p$ restricted to any line is a polynomial of degree at most $3J^{1/_3}$.
Because each line has, by contradiction hypothesis, at least $3 J^{1/_3} + 1$ joints, this polynomial must be identically zero in each line.

It follows that all directional derivatives of $p$ at each joint $\vj$ vanish, so $q(\vj) = 0$.
Furthermore, $q$ also satisfies item 3 and has smaller degree than $p$.
By minimality, we must have $q \equiv 0$, which means that 
$$ p(x, y, z ) = ax +by + cz \, ,$$
for some coefficients $a, b, c$.


We conclude the proof by acting on induction. For $N = 3$ we necessarily have $J\leq 1 \leq 3^{3/_2} 3^{3/_2}$.
No consider a collection of lines $\mathcal L$, and find the one line $\ell \in \mathcal L$ that has at most $3 J^{1/_3}$ joints.
By induction hypothesis, there are at most $3^{3/_2} (N-1)^{3/_2}$ joints in $\mathcal L \setminus \{\ell \}$, so 
$$ J \leq 3 J^{1/_3} + 3^{3/_2} (N-1)^{3/_2}\, , $$
as desired.
\end{proof}

\subsection*{Aknowledgments}
The author is supported by the Max Planck institute for the sciences. 
These notes are based on a lecture by Benny Sudakov at ETH, in 2014.

\bibliographystyle{alpha}
\bibliography{bibli}



\end{document}
